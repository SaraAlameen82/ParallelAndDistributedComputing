{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Parallelism with Machine Learning: The Housing Prices Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the competition\n",
    "\n",
    "- The Housing Prices Competition train_dataset consists of various features of residential homes in Ames, Iowa, including both quantitative and categorical variables like the size of the property, the number of rooms, year built, and neighborhood quality.\n",
    "- It includes a set of 79 explanatory variables describing almost every aspect of the houses, allowing for in-depth analysis.\n",
    "- *The primary goal* of the competition is to predict **the final price of each home**, in this lab we will use *RandomForests*.\n",
    "- The models are evaluated on Root Mean Squared Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price, encouraging precise predictions over a range of housing prices.\n",
    "\n",
    "### File descriptions\n",
    "- *train.csv*: the training set used to train the model.\n",
    "- *test.csv*: the test set used to compute the performance of the model.\n",
    "- *train_data_description.txt*: full description of each column.\n",
    "### Useful train_data fields\n",
    "\n",
    "Here's a brief version of what you'll find in the train_data description file.\n",
    "\n",
    "- *SalePrice*: the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "- *MSSubClass*: The building class\n",
    "- *MSZoning*: The general zoning classification\n",
    "\n",
    "Teh train_dataset is acessible here: https://www.kaggle.com/code/dansbecker/random-forests/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare the train_data\n",
    "*If you're curious about this the professor can explain it for you*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
      "Id                                                                              \n",
      "1           60         3         65.0     8450       1         3            3   \n",
      "2           20         3         80.0     9600       1         3            3   \n",
      "3           60         3         68.0    11250       1         0            3   \n",
      "4           70         3         60.0     9550       1         0            3   \n",
      "5           60         3         84.0    14260       1         0            3   \n",
      "\n",
      "    Utilities  LotConfig  LandSlope  ...  GarageQual  GarageCond  PavedDrive  \\\n",
      "Id                                   ...                                       \n",
      "1           0          4          0  ...           4           4           2   \n",
      "2           0          2          0  ...           4           4           2   \n",
      "3           0          4          0  ...           4           4           2   \n",
      "4           0          0          0  ...           4           4           2   \n",
      "5           0          2          0  ...           4           4           2   \n",
      "\n",
      "    WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
      "Id                                                                             \n",
      "1            0           61              0          0            0         0   \n",
      "2          298            0              0          0            0         0   \n",
      "3            0           42              0          0            0         0   \n",
      "4            0           35            272          0            0         0   \n",
      "5          192           84              0          0            0         0   \n",
      "\n",
      "    MiscVal  \n",
      "Id           \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "5         0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the train_dataset\n",
    "file_path = 'train.csv'\n",
    "train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "\n",
    "# Columns to be deleted\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "# Delete the specified columns\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1)\n",
    "\n",
    "# Define the input features (X) and the output (y)\n",
    "X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "y = train_data_cleaned['SalePrice']\n",
    "\n",
    "# Identify the categorical columns in X\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize a LabelEncoder for each categorical column\n",
    "label_encoders = {column: LabelEncoder() for column in categorical_columns}\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])\n",
    "\n",
    "# Display the first few rows of X to confirm the encoding\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 70), (438, 70), (1022,), (438,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the first dataset (X, y) into train and test sets with a 70% - 30% split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "X_train_filled = X_train.fillna(X_train.median())\n",
    "X_val_filled = X_val.fillna(X_val.median())\n",
    "\n",
    "(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RandomForest Model\n",
    "This is the code for a simple trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation data: 26467.502883356483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_filled = rf_model.predict(X_val_filled)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_filled = sqrt(mean_squared_error(y_val, y_val_pred_filled))\n",
    "\n",
    "# Print the RMSE\n",
    "print(f'RMSE on the validation data: {rmse_filled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Random Forest Model\n",
    "The three most important parameters that typically have the most impact on the performance of a Random Forest model are:\n",
    "\n",
    "- *n_estimators*: This parameter specifies the number of trees in the forest. Generally, a higher number of trees increases the performance and makes the predictions more stable, but it also makes the computation slower. Selecting the right number of trees requires balancing between performance and computational efficiency.\n",
    "\n",
    "- *max_features*: This parameter defines the maximum number of features that are allowed to try in an individual tree. There are several options available for this parameter:\n",
    "\n",
    "    - *sqrt*: This is commonly used and means that the maximum number of features used at each split is the square root of the total number of features.\n",
    "    - *log2*: This is another typical option, meaning the log base 2 of the feature count is used.\n",
    "    - *A specific integer or float*: You can specify an exact number or a proportion of the total.\n",
    "\n",
    "- *max_depth*: This parameter specifies the maximum depth of each tree. Deeper trees can model more complex patterns, but they also risk overfitting. Limiting the depth of trees can improve the model's generalization and reduce overfitting. It's often useful to set this parameter to a finite value, especially when dealing with a large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best parameters sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34155.52179235385, MAPE: 13.875180501812617%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30338.849097862072, MAPE: 11.190218719469183%\n",
      "The parameters: 10, sqrt, 20. RMSE: 29045.13441969273, MAPE: 10.999582155703044%\n",
      "The parameters: 10, sqrt, None. RMSE: 29857.88816585078, MAPE: 11.14923996984299%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34660.965531334085, MAPE: 13.934933036220679%\n",
      "The parameters: 10, log2, 10. RMSE: 29780.885879712325, MAPE: 11.321326655556458%\n",
      "The parameters: 10, log2, 20. RMSE: 30274.052578164188, MAPE: 11.09443886088674%\n",
      "The parameters: 10, log2, None. RMSE: 28781.501496629386, MAPE: 11.219414776631876%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 10, None, 5. RMSE: 30960.58225967296, MAPE: 12.32384363571666%\n",
      "The parameters: 10, None, 10. RMSE: 27164.637288179798, MAPE: 10.44625977692836%\n",
      "The parameters: 10, None, 20. RMSE: 28408.895302918936, MAPE: 10.278452237763865%\n",
      "The parameters: 10, None, None. RMSE: 28237.086404697002, MAPE: 10.308582522258494%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32392.775596489402, MAPE: 13.12359218784406%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28331.536630947146, MAPE: 10.437596337310444%\n",
      "The parameters: 25, sqrt, 20. RMSE: 27703.579286367563, MAPE: 10.341478666166964%\n",
      "The parameters: 25, sqrt, None. RMSE: 27915.141207844463, MAPE: 10.44040387081493%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, 5. RMSE: 34202.718423824896, MAPE: 13.538833983322862%\n",
      "The parameters: 25, log2, 10. RMSE: 29011.19233303979, MAPE: 10.694357441794194%\n",
      "The parameters: 25, log2, 20. RMSE: 28562.351741008268, MAPE: 10.211078514185518%\n",
      "The parameters: 25, log2, None. RMSE: 27461.466579530228, MAPE: 10.271883480171837%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 25, None, 5. RMSE: 30612.610785222438, MAPE: 12.283516668139159%\n",
      "The parameters: 25, None, 10. RMSE: 27118.01481343079, MAPE: 10.296328670480602%\n",
      "The parameters: 25, None, 20. RMSE: 27686.971177900497, MAPE: 10.083368858184926%\n",
      "The parameters: 25, None, None. RMSE: 27016.337172353313, MAPE: 10.068829489304006%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32995.10001647349, MAPE: 12.792834171447915%\n",
      "The parameters: 50, sqrt, 10. RMSE: 27654.681345842644, MAPE: 10.33483523093388%\n",
      "The parameters: 50, sqrt, 20. RMSE: 27332.288264015333, MAPE: 10.175362869648936%\n",
      "The parameters: 50, sqrt, None. RMSE: 28682.33033051863, MAPE: 10.388689614231762%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 5. RMSE: 35279.44855968172, MAPE: 13.262109755952494%\n",
      "The parameters: 50, log2, 10. RMSE: 28626.177945271316, MAPE: 10.524940778598976%\n",
      "The parameters: 50, log2, 20. RMSE: 27914.322463641653, MAPE: 10.168732103097742%\n",
      "The parameters: 50, log2, None. RMSE: 27552.946986419756, MAPE: 10.24802865580257%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, None, 5. RMSE: 30571.294836710535, MAPE: 12.24583174730492%\n",
      "The parameters: 50, None, 10. RMSE: 26563.95874049225, MAPE: 10.18759574623919%\n",
      "The parameters: 50, None, 20. RMSE: 27139.6559660105, MAPE: 9.951765654762191%\n",
      "The parameters: 50, None, None. RMSE: 26722.32749732441, MAPE: 9.98979081359007%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60537.474850632694, MAPE: 25.057060729227725%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48526.19663112171, MAPE: 19.149613320776183%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32677.00969641224, MAPE: 12.516095423159165%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27712.92702956205, MAPE: 10.24757976360254%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27057.271791478375, MAPE: 10.154873541866346%\n",
      "The parameters: 100, sqrt, None. RMSE: 27459.005474258887, MAPE: 10.091639221953061%\n",
      "The parameters: 100, log2, 1. RMSE: 62217.25120830451, MAPE: 25.995436094649797%\n",
      "The parameters: 100, log2, 2. RMSE: 50049.52243506567, MAPE: 19.927458666360316%\n",
      "The parameters: 100, log2, 5. RMSE: 34520.04391621351, MAPE: 13.208188631061587%\n",
      "The parameters: 100, log2, 10. RMSE: 28157.7690883422, MAPE: 10.476826135079964%\n",
      "The parameters: 100, log2, 20. RMSE: 27156.746909260608, MAPE: 9.987685566890129%\n",
      "The parameters: 100, log2, None. RMSE: 27047.97348318936, MAPE: 10.086050722963755%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 100, None, 5. RMSE: 30158.208799910935, MAPE: 12.085257047184603%\n",
      "The parameters: 100, None, 10. RMSE: 26229.623465803226, MAPE: 10.082249680657279%\n",
      "The parameters: 100, None, 20. RMSE: 26694.97855487029, MAPE: 9.929623167001136%\n",
      "The parameters: 100, None, None. RMSE: 26467.502883356483, MAPE: 9.94230329364309%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60606.77404540022, MAPE: 25.38780466142814%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48513.864359636864, MAPE: 19.337554340742162%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32993.18871121931, MAPE: 12.61612051325727%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28138.728456668545, MAPE: 10.191267508917718%\n",
      "The parameters: 200, sqrt, 20. RMSE: 26992.54963309898, MAPE: 10.005495692938336%\n",
      "The parameters: 200, sqrt, None. RMSE: 27470.259673002172, MAPE: 9.957796194290632%\n",
      "The parameters: 200, log2, 1. RMSE: 62156.591988988555, MAPE: 26.400545893269207%\n",
      "The parameters: 200, log2, 2. RMSE: 50100.71822331239, MAPE: 20.16959331393044%\n",
      "The parameters: 200, log2, 5. RMSE: 34728.77296217778, MAPE: 13.34186990074812%\n",
      "The parameters: 200, log2, 10. RMSE: 28540.588801066686, MAPE: 10.402159696051008%\n",
      "The parameters: 200, log2, 20. RMSE: 27973.57993168901, MAPE: 10.070274127543609%\n",
      "The parameters: 200, log2, None. RMSE: 27828.251251311896, MAPE: 10.169611462609703%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, None, 5. RMSE: 30043.612349616717, MAPE: 12.029112075981505%\n",
      "The parameters: 200, None, 10. RMSE: 26324.169429650326, MAPE: 9.98955657065506%\n",
      "The parameters: 200, None, 20. RMSE: 26432.80360372722, MAPE: 9.822626849321718%\n",
      "The parameters: 200, None, None. RMSE: 26361.368122850155, MAPE: 9.834185950285752%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60939.44710825578, MAPE: 25.550776077914072%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48515.860515194436, MAPE: 19.47427696390715%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32771.68197049856, MAPE: 12.674299550845117%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27897.501250583955, MAPE: 10.13341432065161%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27133.6312643469, MAPE: 9.913106477514967%\n",
      "The parameters: 300, sqrt, None. RMSE: 27346.638310372637, MAPE: 9.863642103340164%\n",
      "The parameters: 300, log2, 1. RMSE: 62706.94857828937, MAPE: 26.579274369922068%\n",
      "The parameters: 300, log2, 2. RMSE: 50494.27897059568, MAPE: 20.300368805638698%\n",
      "The parameters: 300, log2, 5. RMSE: 34508.111473100915, MAPE: 13.330231247693854%\n",
      "The parameters: 300, log2, 10. RMSE: 28513.003997954456, MAPE: 10.393018610008083%\n",
      "The parameters: 300, log2, 20. RMSE: 27869.068911267663, MAPE: 10.032801453886307%\n",
      "The parameters: 300, log2, None. RMSE: 27714.459564901135, MAPE: 10.126951400294839%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, None, 5. RMSE: 30038.24412207254, MAPE: 12.041707760485556%\n",
      "The parameters: 300, None, 10. RMSE: 26458.792091411793, MAPE: 9.971788649787706%\n",
      "The parameters: 300, None, 20. RMSE: 26446.682269631146, MAPE: 9.838940381965923%\n",
      "The parameters: 300, None, None. RMSE: 26350.22609926069, MAPE: 9.85329034398722%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60921.977002566455, MAPE: 25.53947832070904%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48701.07681453854, MAPE: 19.54560413109822%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32872.23978904568, MAPE: 12.736148071083697%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27864.12004756174, MAPE: 10.099552920868485%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27012.22254845255, MAPE: 9.883418730916587%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.8238673839, MAPE: 9.868552663684156%\n",
      "The parameters: 400, log2, 1. RMSE: 62679.44788059154, MAPE: 26.465389497537085%\n",
      "The parameters: 400, log2, 2. RMSE: 50451.28682012395, MAPE: 20.255285226640495%\n",
      "The parameters: 400, log2, 5. RMSE: 34407.08469567501, MAPE: 13.30417205172344%\n",
      "The parameters: 400, log2, 10. RMSE: 28425.165592458347, MAPE: 10.402413216120628%\n",
      "The parameters: 400, log2, 20. RMSE: 27875.795613134695, MAPE: 9.9971828182334%\n",
      "The parameters: 400, log2, None. RMSE: 27839.861170615546, MAPE: 10.089019580009861%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, None, 5. RMSE: 30237.33419582336, MAPE: 12.053440817906347%\n",
      "The parameters: 400, None, 10. RMSE: 26574.762830117787, MAPE: 9.974836471357253%\n",
      "The parameters: 400, None, 20. RMSE: 26552.955357527637, MAPE: 9.857159238803634%\n",
      "The parameters: 400, None, None. RMSE: 26493.752047262402, MAPE: 9.874439964682043%\n",
      "\n",
      "Sequential Execution:\n",
      "Best Parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': 10}, RMSE: 26229.623465803226, MAPE: 10.082249680657279%\n",
      "Execution Time: 129.042973279953 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "\n",
    "# Define the parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit\n",
    "\n",
    "\n",
    "# Function to evaluate all parameter combinations\n",
    "def evaluate_combinations(n_estimators_range, max_features_range, max_depth_range, X_train_filled, y_train, X_val_filled, y_val):\n",
    "    best_rmse = float('inf')\n",
    "    best_mape = float('inf')\n",
    "    best_model = None\n",
    "    best_parameters = {}\n",
    "\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_features in max_features_range:\n",
    "            for max_depth in max_depth_range:\n",
    "                # Create and train the Random Forest model\n",
    "                rf_model = RandomForestRegressor(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_features=max_features,\n",
    "                    max_depth=max_depth,\n",
    "                    random_state=42\n",
    "                )\n",
    "                rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "                # Make predictions and compute RMSE\n",
    "                y_val_pred = rf_model.predict(X_val_filled)\n",
    "                rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "                mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "\n",
    "                # Print parameters and metrics\n",
    "                print(f\"The parameters: {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "\n",
    "                # Update the best model if this one is better\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_mape = mape\n",
    "                    best_model = rf_model\n",
    "                    best_parameters = {\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'max_features': max_features,\n",
    "                        'max_depth': max_depth\n",
    "                    }\n",
    "\n",
    "    return best_rmse, best_mape, best_model, best_parameters\n",
    "\n",
    "\n",
    "# Sequential Execution\n",
    "start_time = time.time()\n",
    "\n",
    "best_rmse_seq, best_mape_seq, best_model_seq, best_params_seq = evaluate_combinations(\n",
    "    n_estimators_range,\n",
    "    max_features_range,\n",
    "    max_depth_range,\n",
    "    X_train_filled,\n",
    "    y_train,\n",
    "    X_val_filled,\n",
    "    y_val\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "sequential_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nSequential Execution:\")\n",
    "print(f\"Best Parameters: {best_params_seq}, RMSE: {best_rmse_seq}, MAPE: {best_mape_seq}%\")\n",
    "print(f\"Execution Time: {sequential_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters: 10, sqrt, 1. RMSE: 62936.129262244904, MAPE: 26.860734529882123%\n",
      "The parameters: 10, sqrt, 2. RMSE: 51806.105176310826, MAPE: 20.52147680573829%\n",
      "The parameters: 10, sqrt, 5. RMSE: 34155.52179235385, MAPE: 13.875180501812617%\n",
      "The parameters: 10, sqrt, 10. RMSE: 30338.849097862072, MAPE: 11.190218719469183%\n",
      "The parameters: 100, sqrt, 1. RMSE: 60537.474850632694, MAPE: 25.057060729227725%\n",
      "The parameters: 10, sqrt, 20. RMSE: 29045.13441969273, MAPE: 10.999582155703044%\n",
      "The parameters: 10, sqrt, None. RMSE: 29857.88816585078, MAPE: 11.14923996984299%\n",
      "The parameters: 10, log2, 1. RMSE: 64442.107292878405, MAPE: 27.58882909655716%\n",
      "The parameters: 100, sqrt, 2. RMSE: 48526.19663112171, MAPE: 19.149613320776183%\n",
      "The parameters: 10, log2, 2. RMSE: 51396.530250771764, MAPE: 21.498982900746558%\n",
      "The parameters: 10, log2, 5. RMSE: 34660.965531334085, MAPE: 13.934933036220679%\n",
      "The parameters: 10, log2, 10. RMSE: 29780.885879712325, MAPE: 11.321326655556458%\n",
      "The parameters: 10, log2, 20. RMSE: 30274.052578164188, MAPE: 11.09443886088674%\n",
      "The parameters: 10, log2, None. RMSE: 28781.501496629386, MAPE: 11.219414776631876%\n",
      "The parameters: 10, None, 1. RMSE: 57823.30960766656, MAPE: 25.854236053260713%\n",
      "The parameters: 10, None, 2. RMSE: 44738.9675013081, MAPE: 19.39967435427367%\n",
      "The parameters: 100, sqrt, 5. RMSE: 32677.00969641224, MAPE: 12.516095423159165%\n",
      "The parameters: 10, None, 5. RMSE: 30960.58225967296, MAPE: 12.32384363571666%\n",
      "The parameters: 10, None, 10. RMSE: 27164.637288179798, MAPE: 10.44625977692836%\n",
      "The parameters: 100, sqrt, 10. RMSE: 27712.92702956205, MAPE: 10.24757976360254%\n",
      "The parameters: 10, None, 20. RMSE: 28408.895302918936, MAPE: 10.278452237763865%\n",
      "The parameters: 10, None, None. RMSE: 28237.086404697002, MAPE: 10.308582522258494%\n",
      "The parameters: 25, sqrt, 1. RMSE: 60720.06723428002, MAPE: 25.2463033064465%\n",
      "The parameters: 25, sqrt, 2. RMSE: 48999.969822412146, MAPE: 19.141115612087532%\n",
      "The parameters: 25, sqrt, 5. RMSE: 32392.775596489402, MAPE: 13.12359218784406%\n",
      "The parameters: 100, sqrt, 20. RMSE: 27057.271791478375, MAPE: 10.154873541866346%\n",
      "The parameters: 25, sqrt, 10. RMSE: 28331.536630947146, MAPE: 10.437596337310444%\n",
      "The parameters: 25, sqrt, 20. RMSE: 27703.579286367563, MAPE: 10.341478666166964%\n",
      "The parameters: 25, sqrt, None. RMSE: 27915.141207844463, MAPE: 10.44040387081493%\n",
      "The parameters: 25, log2, 1. RMSE: 62175.23336548907, MAPE: 26.103334605968907%\n",
      "The parameters: 25, log2, 2. RMSE: 49454.96222058965, MAPE: 20.009887677109557%\n",
      "The parameters: 25, log2, 5. RMSE: 34202.718423824896, MAPE: 13.538833983322862%\n",
      "The parameters: 25, log2, 10. RMSE: 29011.19233303979, MAPE: 10.694357441794194%\n",
      "The parameters: 100, sqrt, None. RMSE: 27459.005474258887, MAPE: 10.091639221953061%\n",
      "The parameters: 25, log2, 20. RMSE: 28562.351741008268, MAPE: 10.211078514185518%\n",
      "The parameters: 100, log2, 1. RMSE: 62217.25120830451, MAPE: 25.995436094649797%\n",
      "The parameters: 25, log2, None. RMSE: 27461.466579530228, MAPE: 10.271883480171837%\n",
      "The parameters: 100, log2, 2. RMSE: 50049.52243506567, MAPE: 19.927458666360316%\n",
      "The parameters: 25, None, 1. RMSE: 57545.23094798376, MAPE: 25.562043938945223%\n",
      "The parameters: 25, None, 2. RMSE: 44503.99568777034, MAPE: 18.93356623365525%\n",
      "The parameters: 100, log2, 5. RMSE: 34520.04391621351, MAPE: 13.208188631061587%\n",
      "The parameters: 25, None, 5. RMSE: 30612.610785222438, MAPE: 12.283516668139159%\n",
      "The parameters: 100, log2, 10. RMSE: 28157.7690883422, MAPE: 10.476826135079964%\n",
      "The parameters: 25, None, 10. RMSE: 27118.01481343079, MAPE: 10.296328670480602%\n",
      "The parameters: 100, log2, 20. RMSE: 27156.746909260608, MAPE: 9.987685566890129%\n",
      "The parameters: 25, None, 20. RMSE: 27686.971177900497, MAPE: 10.083368858184926%\n",
      "The parameters: 100, log2, None. RMSE: 27047.97348318936, MAPE: 10.086050722963755%\n",
      "The parameters: 100, None, 1. RMSE: 57211.16615127391, MAPE: 25.025965875120264%\n",
      "The parameters: 25, None, None. RMSE: 27016.337172353313, MAPE: 10.068829489304006%\n",
      "The parameters: 50, sqrt, 1. RMSE: 60346.5737195233, MAPE: 25.162121091064353%\n",
      "The parameters: 50, sqrt, 2. RMSE: 48952.98192411672, MAPE: 19.219570888426375%\n",
      "The parameters: 50, sqrt, 5. RMSE: 32995.10001647349, MAPE: 12.792834171447915%\n",
      "The parameters: 100, None, 2. RMSE: 44472.47296968139, MAPE: 18.836095197090465%\n",
      "The parameters: 50, sqrt, 10. RMSE: 27654.681345842644, MAPE: 10.33483523093388%\n",
      "The parameters: 50, sqrt, 20. RMSE: 27332.288264015333, MAPE: 10.175362869648936%\n",
      "The parameters: 50, sqrt, None. RMSE: 28682.33033051863, MAPE: 10.388689614231762%\n",
      "The parameters: 50, log2, 1. RMSE: 61769.11746990103, MAPE: 26.024888854218215%\n",
      "The parameters: 50, log2, 2. RMSE: 49973.37697266408, MAPE: 19.855069340876533%\n",
      "The parameters: 50, log2, 5. RMSE: 35279.44855968172, MAPE: 13.262109755952494%\n",
      "The parameters: 100, None, 5. RMSE: 30158.208799910935, MAPE: 12.085257047184603%\n",
      "The parameters: 50, log2, 10. RMSE: 28626.177945271316, MAPE: 10.524940778598976%\n",
      "The parameters: 50, log2, 20. RMSE: 27914.322463641653, MAPE: 10.168732103097742%\n",
      "The parameters: 50, log2, None. RMSE: 27552.946986419756, MAPE: 10.24802865580257%\n",
      "The parameters: 50, None, 1. RMSE: 57505.08832414332, MAPE: 25.40677081979206%\n",
      "The parameters: 50, None, 2. RMSE: 44571.23631103615, MAPE: 18.993732376822592%\n",
      "The parameters: 50, None, 5. RMSE: 30571.294836710535, MAPE: 12.24583174730492%\n",
      "The parameters: 100, None, 10. RMSE: 26229.623465803226, MAPE: 10.082249680657279%\n",
      "The parameters: 50, None, 10. RMSE: 26563.95874049225, MAPE: 10.18759574623919%\n",
      "The parameters: 50, None, 20. RMSE: 27139.6559660105, MAPE: 9.951765654762191%\n",
      "The parameters: 100, None, 20. RMSE: 26694.97855487029, MAPE: 9.929623167001136%\n",
      "The parameters: 50, None, None. RMSE: 26722.32749732441, MAPE: 9.98979081359007%\n",
      "The parameters: 100, None, None. RMSE: 26467.502883356483, MAPE: 9.94230329364309%\n",
      "The parameters: 200, sqrt, 1. RMSE: 60606.77404540022, MAPE: 25.38780466142814%\n",
      "The parameters: 200, sqrt, 2. RMSE: 48513.864359636864, MAPE: 19.337554340742162%\n",
      "The parameters: 200, sqrt, 5. RMSE: 32993.18871121931, MAPE: 12.61612051325727%\n",
      "The parameters: 200, sqrt, 10. RMSE: 28138.728456668545, MAPE: 10.191267508917718%\n",
      "The parameters: 200, sqrt, 20. RMSE: 26992.54963309898, MAPE: 10.005495692938336%\n",
      "The parameters: 200, sqrt, None. RMSE: 27470.259673002172, MAPE: 9.957796194290632%\n",
      "The parameters: 200, log2, 1. RMSE: 62156.591988988555, MAPE: 26.400545893269207%\n",
      "The parameters: 200, log2, 2. RMSE: 50100.71822331239, MAPE: 20.16959331393044%\n",
      "The parameters: 200, log2, 5. RMSE: 34728.77296217778, MAPE: 13.34186990074812%\n",
      "The parameters: 200, log2, 10. RMSE: 28540.588801066686, MAPE: 10.402159696051008%\n",
      "The parameters: 200, log2, 20. RMSE: 27973.57993168901, MAPE: 10.070274127543609%\n",
      "The parameters: 200, log2, None. RMSE: 27828.251251311896, MAPE: 10.169611462609703%\n",
      "The parameters: 200, None, 1. RMSE: 57330.65911329287, MAPE: 25.203756111774418%\n",
      "The parameters: 200, None, 2. RMSE: 44545.47770035227, MAPE: 18.8459387073764%\n",
      "The parameters: 200, None, 5. RMSE: 30043.612349616717, MAPE: 12.029112075981505%\n",
      "The parameters: 200, None, 10. RMSE: 26324.169429650326, MAPE: 9.98955657065506%\n",
      "The parameters: 200, None, 20. RMSE: 26432.80360372722, MAPE: 9.822626849321718%\n",
      "The parameters: 200, None, None. RMSE: 26361.368122850155, MAPE: 9.834185950285752%\n",
      "The parameters: 300, sqrt, 1. RMSE: 60939.44710825578, MAPE: 25.550776077914072%\n",
      "The parameters: 300, sqrt, 2. RMSE: 48515.860515194436, MAPE: 19.47427696390715%\n",
      "The parameters: 300, sqrt, 5. RMSE: 32771.68197049856, MAPE: 12.674299550845117%\n",
      "The parameters: 300, sqrt, 10. RMSE: 27897.501250583955, MAPE: 10.13341432065161%\n",
      "The parameters: 300, sqrt, 20. RMSE: 27133.6312643469, MAPE: 9.913106477514967%\n",
      "The parameters: 300, sqrt, None. RMSE: 27346.638310372637, MAPE: 9.863642103340164%\n",
      "The parameters: 300, log2, 1. RMSE: 62706.94857828937, MAPE: 26.579274369922068%\n",
      "The parameters: 300, log2, 2. RMSE: 50494.27897059568, MAPE: 20.300368805638698%\n",
      "The parameters: 300, log2, 5. RMSE: 34508.111473100915, MAPE: 13.330231247693854%\n",
      "The parameters: 300, log2, 10. RMSE: 28513.003997954456, MAPE: 10.393018610008083%\n",
      "The parameters: 300, log2, 20. RMSE: 27869.068911267663, MAPE: 10.032801453886307%\n",
      "The parameters: 300, log2, None. RMSE: 27714.459564901135, MAPE: 10.126951400294839%\n",
      "The parameters: 300, None, 1. RMSE: 57645.45868384868, MAPE: 25.615849754017994%\n",
      "The parameters: 300, None, 2. RMSE: 44468.13497206259, MAPE: 18.973613128632305%\n",
      "The parameters: 300, None, 5. RMSE: 30038.24412207254, MAPE: 12.041707760485556%\n",
      "The parameters: 300, None, 10. RMSE: 26458.792091411793, MAPE: 9.971788649787706%\n",
      "The parameters: 300, None, 20. RMSE: 26446.682269631146, MAPE: 9.838940381965923%\n",
      "The parameters: 300, None, None. RMSE: 26350.22609926069, MAPE: 9.85329034398722%\n",
      "The parameters: 400, sqrt, 1. RMSE: 60921.977002566455, MAPE: 25.53947832070904%\n",
      "The parameters: 400, sqrt, 2. RMSE: 48701.07681453854, MAPE: 19.54560413109822%\n",
      "The parameters: 400, sqrt, 5. RMSE: 32872.23978904568, MAPE: 12.736148071083697%\n",
      "The parameters: 400, sqrt, 10. RMSE: 27864.12004756174, MAPE: 10.099552920868485%\n",
      "The parameters: 400, sqrt, 20. RMSE: 27012.22254845255, MAPE: 9.883418730916587%\n",
      "The parameters: 400, sqrt, None. RMSE: 27418.8238673839, MAPE: 9.868552663684156%\n",
      "The parameters: 400, log2, 1. RMSE: 62679.44788059154, MAPE: 26.465389497537085%\n",
      "The parameters: 400, log2, 2. RMSE: 50451.28682012395, MAPE: 20.255285226640495%\n",
      "The parameters: 400, log2, 5. RMSE: 34407.08469567501, MAPE: 13.30417205172344%\n",
      "The parameters: 400, log2, 10. RMSE: 28425.165592458347, MAPE: 10.402413216120628%\n",
      "The parameters: 400, log2, 20. RMSE: 27875.795613134695, MAPE: 9.9971828182334%\n",
      "The parameters: 400, log2, None. RMSE: 27839.861170615546, MAPE: 10.089019580009861%\n",
      "The parameters: 400, None, 1. RMSE: 57795.7474853705, MAPE: 25.753019610226186%\n",
      "The parameters: 400, None, 2. RMSE: 44508.690046548625, MAPE: 19.00415009775348%\n",
      "The parameters: 400, None, 5. RMSE: 30237.33419582336, MAPE: 12.053440817906347%\n",
      "The parameters: 400, None, 10. RMSE: 26574.762830117787, MAPE: 9.974836471357253%\n",
      "The parameters: 400, None, 20. RMSE: 26552.955357527637, MAPE: 9.857159238803634%\n",
      "The parameters: 400, None, None. RMSE: 26493.752047262402, MAPE: 9.874439964682043%\n",
      "\n",
      "Threading Execution:\n",
      "Best Parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': 10}, RMSE: 26229.6235, MAPE: 10.08%\n",
      "Execution Time: 122.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Implementing Threads\n",
    "\n",
    "import threading\n",
    "\n",
    "# Thread-safe list to store results and lock for printing\n",
    "lock = threading.Lock()\n",
    "results_threading = []\n",
    "\n",
    "# Thread function to evaluate combinations\n",
    "def thread_worker(param_ranges):\n",
    "    rmse, mape, model, params = evaluate_combinations(\n",
    "        param_ranges[0], param_ranges[1], param_ranges[2],\n",
    "        X_train_filled, y_train, X_val_filled, y_val\n",
    "    )\n",
    "    with lock:\n",
    "        results_threading.append((rmse, mape, params))\n",
    "\n",
    "# Split parameter ranges into chunks (e.g., by splitting `n_estimators_range`)\n",
    "chunks = [n_estimators_range[:len(n_estimators_range)//2], n_estimators_range[len(n_estimators_range)//2:]]\n",
    "\n",
    "threads = []\n",
    "start_time = time.time()\n",
    "\n",
    "for chunk in chunks:\n",
    "    thread = threading.Thread(target=thread_worker, args=([chunk, max_features_range, max_depth_range],))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = time.time()\n",
    "threading_time = end_time - start_time\n",
    "\n",
    "# Find the best result from all threads\n",
    "best_threading_result = min(results_threading, key=lambda x: x[0])\n",
    "\n",
    "print(f\"\\nThreading Execution:\")\n",
    "print(f\"Best Parameters: {best_threading_result[2]}, RMSE: {best_threading_result[0]:.4f}, MAPE: {best_threading_result[1]:.2f}%\")\n",
    "print(f\"Execution Time: {threading_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_estimators_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluate_combinations(\n\u001b[0;32m      8\u001b[0m         param_ranges[\u001b[38;5;241m0\u001b[39m], param_ranges[\u001b[38;5;241m1\u001b[39m], param_ranges[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      9\u001b[0m         X_train_filled, y_train, X_val_filled, y_val\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Split parameter ranges into chunks (e.g., by splitting `n_estimators_range`)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m chunks \u001b[38;5;241m=\u001b[39m [\u001b[43mn_estimators_range\u001b[49m[:\u001b[38;5;28mlen\u001b[39m(n_estimators_range)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m], n_estimators_range[\u001b[38;5;28mlen\u001b[39m(n_estimators_range)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m:]]\n\u001b[0;32m     15\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool() \u001b[38;5;28;01mas\u001b[39;00m pool:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_estimators_range' is not defined"
     ]
    }
   ],
   "source": [
    "# Implementing Processes\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Multiprocessing worker function (evaluates a subset of parameter combinations)\n",
    "def process_worker(param_ranges):\n",
    "    return evaluate_combinations(\n",
    "        param_ranges[0], param_ranges[1], param_ranges[2],\n",
    "        X_train_filled, y_train, X_val_filled, y_val\n",
    "    )\n",
    "\n",
    "# Split parameter ranges into chunks (e.g., by splitting `n_estimators_range`)\n",
    "chunks = [n_estimators_range[:len(n_estimators_range)//2], n_estimators_range[len(n_estimators_range)//2:]]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with Pool() as pool:\n",
    "    multiprocessing_results = pool.map(\n",
    "        process_worker,\n",
    "        [(chunk, max_features_range, max_depth_range) for chunk in chunks]\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "multiprocessing_time = end_time - start_time\n",
    "\n",
    "# Find the best result from all processes\n",
    "best_multiprocessing_result = min(multiprocessing_results, key=lambda x: x[0])\n",
    "\n",
    "print(f\"\\nMultiprocessing Execution:\")\n",
    "print(f\"Best Parameters: {best_multiprocessing_result[3]}, RMSE: {best_multiprocessing_result[0]:.4f}, MAPE: {best_multiprocessing_result[1]:.2f}%\")\n",
    "print(f\"Execution Time: {multiprocessing_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
